{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Listening...\n",
      "Transcribing audio...\n",
      "Transcription: my name is Karim and I want to go to the beach today my name is Karim and I want to go to the beach today\n",
      "Translation: Mi nombre es Karim y quiero ir a la playa hoy. Mi nombre es Karim y quiero ir a la playa hoy.\n",
      "Listening...\n",
      "Transcribing audio...\n",
      "Transcription: the first thing I wanted to do when I landed in Dubai was ordered a burger to eat as it is my favourite food\n",
      "Translation: La primera cosa que quise hacer cuando lleguÃ© a Dubai fue pedir una hamburguesa para comer, ya que es mi comida favorita.\n",
      "Listening...\n",
      "Transcribing audio...\n",
      "Google Speech Recognition could not understand audio\n",
      "Listening...\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 62\u001b[0m\n\u001b[1;32m     59\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m translation\n\u001b[1;32m     61\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m---> 62\u001b[0m     access_webcam()\n",
      "Cell \u001b[0;32mIn[1], line 24\u001b[0m, in \u001b[0;36maccess_webcam\u001b[0;34m()\u001b[0m\n\u001b[1;32m     22\u001b[0m     recognizer\u001b[38;5;241m.\u001b[39madjust_for_ambient_noise(source)\n\u001b[1;32m     23\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mListening...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 24\u001b[0m     audio \u001b[38;5;241m=\u001b[39m recognizer\u001b[38;5;241m.\u001b[39mlisten(source)\n\u001b[1;32m     26\u001b[0m text \u001b[38;5;241m=\u001b[39m transcribe_audio(recognizer, audio)\n\u001b[1;32m     27\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m text:\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/speech_recognition/__init__.py:523\u001b[0m, in \u001b[0;36mRecognizer.listen\u001b[0;34m(self, source, timeout, phrase_time_limit, snowboy_configuration)\u001b[0m\n\u001b[1;32m    520\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m phrase_time_limit \u001b[38;5;129;01mand\u001b[39;00m elapsed_time \u001b[38;5;241m-\u001b[39m phrase_start_time \u001b[38;5;241m>\u001b[39m phrase_time_limit:\n\u001b[1;32m    521\u001b[0m     \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[0;32m--> 523\u001b[0m buffer \u001b[38;5;241m=\u001b[39m source\u001b[38;5;241m.\u001b[39mstream\u001b[38;5;241m.\u001b[39mread(source\u001b[38;5;241m.\u001b[39mCHUNK)\n\u001b[1;32m    524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(buffer) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m: \u001b[38;5;28;01mbreak\u001b[39;00m  \u001b[38;5;66;03m# reached end of the stream\u001b[39;00m\n\u001b[1;32m    525\u001b[0m frames\u001b[38;5;241m.\u001b[39mappend(buffer)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/speech_recognition/__init__.py:199\u001b[0m, in \u001b[0;36mMicrophone.MicrophoneStream.read\u001b[0;34m(self, size)\u001b[0m\n\u001b[1;32m    198\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mread\u001b[39m(\u001b[38;5;28mself\u001b[39m, size):\n\u001b[0;32m--> 199\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpyaudio_stream\u001b[38;5;241m.\u001b[39mread(size, exception_on_overflow\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/pyaudio/__init__.py:570\u001b[0m, in \u001b[0;36mPyAudio.Stream.read\u001b[0;34m(self, num_frames, exception_on_overflow)\u001b[0m\n\u001b[1;32m    567\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_is_input:\n\u001b[1;32m    568\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mIOError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNot input stream\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    569\u001b[0m                   paCanNotReadFromAnOutputOnlyStream)\n\u001b[0;32m--> 570\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m pa\u001b[38;5;241m.\u001b[39mread_stream(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_stream, num_frames,\n\u001b[1;32m    571\u001b[0m                       exception_on_overflow)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import speech_recognition as sr\n",
    "import openai\n",
    "\n",
    "# Set your OpenAI API key\n",
    "openai.api_key = 'sk-proj-psYgAG0WCYoAV1BpRGxUT3BlbkFJ7dPOC3wvamMAVBXpUUmj'\n",
    "\n",
    "def access_webcam():\n",
    "    cap = cv2.VideoCapture(0)\n",
    "    recognizer = sr.Recognizer()\n",
    "    microphone = sr.Microphone()\n",
    "\n",
    "    while True:\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "\n",
    "        cv2.imshow('Webcam', frame)\n",
    "\n",
    "        # Capture and transcribe audio\n",
    "        with microphone as source:\n",
    "            recognizer.adjust_for_ambient_noise(source)\n",
    "            print(\"Listening...\")\n",
    "            audio = recognizer.listen(source)\n",
    "\n",
    "        text = transcribe_audio(recognizer, audio)\n",
    "        if text:\n",
    "            translation = translate_text(text)\n",
    "            cv2.putText(frame, translation, (50, 50), cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 255, 255), 2, cv2.LINE_AA)\n",
    "\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "def transcribe_audio(recognizer, audio):\n",
    "    try:\n",
    "        print(\"Transcribing audio...\")\n",
    "        text = recognizer.recognize_google(audio)\n",
    "        print(f\"Transcription: {text}\")\n",
    "        return text\n",
    "    except sr.UnknownValueError:\n",
    "        print(\"Google Speech Recognition could not understand audio\")\n",
    "    except sr.RequestError as e:\n",
    "        print(f\"Could not request results from Google Speech Recognition service; {e}\")\n",
    "    return None\n",
    "\n",
    "def translate_text(text, target_language='es'):\n",
    "    response = openai.ChatCompletion.create(\n",
    "        model=\"gpt-3.5-turbo\",\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
    "            {\"role\": \"user\", \"content\": f\"Translate the following text to {target_language}:\\n{text}\"}\n",
    "        ]\n",
    "    )\n",
    "    translation = response.choices[0].message['content'].strip()\n",
    "    print(f\"Translation: {translation}\")\n",
    "    return translation\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    access_webcam()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'function' object has no attribute '_root_container'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[13], line 48\u001b[0m\n\u001b[1;32m     45\u001b[0m             st\u001b[38;5;241m.\u001b[39mtext_area(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTranslated Text\u001b[39m\u001b[38;5;124m\"\u001b[39m, translation, height\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m300\u001b[39m)\n\u001b[1;32m     47\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m---> 48\u001b[0m     main()\n",
      "Cell \u001b[0;32mIn[13], line 27\u001b[0m, in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mmain\u001b[39m():\n\u001b[0;32m---> 27\u001b[0m     st\u001b[38;5;241m.\u001b[39mtitle(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFile Translator\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     29\u001b[0m     uploaded_file \u001b[38;5;241m=\u001b[39m st\u001b[38;5;241m.\u001b[39mfile_uploader(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUpload a file\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28mtype\u001b[39m\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtxt\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpdf\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[1;32m     30\u001b[0m     target_language \u001b[38;5;241m=\u001b[39m st\u001b[38;5;241m.\u001b[39mtext_input(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEnter the target language (e.g., \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mes\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m for Spanish)\u001b[39m\u001b[38;5;124m\"\u001b[39m, value\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mes\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/streamlit/elements/markdown.py:183\u001b[0m, in \u001b[0;36mMarkdownMixin.title\u001b[0;34m(self, body, anchor)\u001b[0m\n\u001b[1;32m    181\u001b[0m     title_proto\u001b[38;5;241m.\u001b[39mbody \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m<h1 data-anchor=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00manchor\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m>\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mclean_text(body)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m</h1>\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    182\u001b[0m     title_proto\u001b[38;5;241m.\u001b[39mallow_html \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m--> 183\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdg\u001b[38;5;241m.\u001b[39m_enqueue(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmarkdown\u001b[39m\u001b[38;5;124m\"\u001b[39m, title_proto)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/streamlit/delta_generator.py:401\u001b[0m, in \u001b[0;36mDeltaGenerator._enqueue\u001b[0;34m(self, delta_type, element_proto, return_value, last_index, element_width, element_height)\u001b[0m\n\u001b[1;32m    399\u001b[0m \u001b[38;5;66;03m# Only enqueue message and fill in metadata if there's a container.\u001b[39;00m\n\u001b[1;32m    400\u001b[0m msg_was_enqueued \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m--> 401\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m dg\u001b[38;5;241m.\u001b[39m_root_container \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m dg\u001b[38;5;241m.\u001b[39m_cursor \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    402\u001b[0m     msg\u001b[38;5;241m.\u001b[39mmetadata\u001b[38;5;241m.\u001b[39mdelta_path[:] \u001b[38;5;241m=\u001b[39m dg\u001b[38;5;241m.\u001b[39m_cursor\u001b[38;5;241m.\u001b[39mdelta_path\n\u001b[1;32m    404\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m element_width \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'function' object has no attribute '_root_container'"
     ]
    }
   ],
   "source": [
    "import fitz  # PyMuPDF\n",
    "import openai\n",
    "import streamlit as st\n",
    "\n",
    "# Set your OpenAI API key\n",
    "openai.api_key = 'sk-proj-psYgAG0WCYoAV1BpRGxUT3BlbkFJ7dPOC3wvamMAVBXpUUmj'\n",
    "\n",
    "def extract_text_from_pdf(file):\n",
    "    doc = fitz.open(file)\n",
    "    text = \"\"\n",
    "    for page in doc:\n",
    "        text += page.get_text()\n",
    "    return text\n",
    "\n",
    "def translate_text(text, target_language='es'):\n",
    "    response = openai.ChatCompletion.create(\n",
    "        model=\"gpt-3.5-turbo\",\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
    "            {\"role\": \"user\", \"content\": f\"Translate the following text to {target_language}:\\n{text}\"}\n",
    "        ]\n",
    "    )\n",
    "    translation = response.choices[0].message['content'].strip()\n",
    "    return translation\n",
    "\n",
    "def main():\n",
    "    st.title(\"File Translator\")\n",
    "    \n",
    "    uploaded_file = st.file_uploader(\"Upload a file\", type=[\"txt\", \"pdf\"])\n",
    "    target_language = st.text_input(\"Enter the target language (e.g., 'es' for Spanish)\", value=\"es\")\n",
    "\n",
    "    if uploaded_file is not None:\n",
    "        if uploaded_file.type == \"application/pdf\":\n",
    "            text = extract_text_from_pdf(uploaded_file)\n",
    "        elif uploaded_file.type == \"text/plain\":\n",
    "            text = str(uploaded_file.read(), \"utf-8\")\n",
    "        else:\n",
    "            st.error(\"Unsupported file type\")\n",
    "            return\n",
    "\n",
    "        st.text_area(\"Extracted Text\", text, height=300)\n",
    "        \n",
    "        if st.button(\"Translate\"):\n",
    "            translation = translate_text(text, target_language)\n",
    "            st.text_area(\"Translated Text\", translation, height=300)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
